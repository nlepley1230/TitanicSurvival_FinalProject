{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bcf440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309bd429",
   "metadata": {},
   "source": [
    "# Read the CSV and Preform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fe74fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_df = pd.read_csv(\"data/gender_submission.csv\")\n",
    "test_df = pd.read_csv(\"data/test.csv\")\n",
    "train_df = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dd5c88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#checking for null values\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17bb3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Description of dataset\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b693ff41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#detailed look at what is actually missing in data\n",
    "\n",
    "total = train_df.isnull().sum().sort_values(ascending=False)\n",
    "percent_1 = train_df.isnull().sum()/train_df.isnull().count()*100\n",
    "percent_2 = (round(percent_1, 1)).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'])\n",
    "missing_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50689534",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merged test dataset with gender to have is people survived or not.\n",
    "test_merged_df = test_df.merge(gender_df, on='PassengerId')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ee4b3f",
   "metadata": {},
   "source": [
    "Dropped Columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf71963f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non needed columns\n",
    "train_df = train_df.drop(['Ticket'], axis=1)\n",
    "test_merged_df = test_merged_df.drop(['Ticket'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faa9aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['Cabin'], axis=1)\n",
    "test_merged_df = test_merged_df.drop(['Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5193bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['Name'], axis=1)\n",
    "test_merged_df = test_merged_df.drop(['Name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38624f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping na from names\n",
    "train_df = train_df[train_df['Age'].notna()]\n",
    "test_merged_df = test_merged_df[test_df['Age'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4c5b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Making ports numeric\n",
    "# ports = {\"S\": 0, \"C\": 1, \"Q\": 2}\n",
    "# data = [train_df, test_merged_df]\n",
    "\n",
    "# for dataset in data:\n",
    "#     dataset['Embarked'] = dataset['Embarked'].map(ports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dab333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Embarked feature has only 2 missing values, filled in with most common\n",
    "# common_value = 'S'\n",
    "# data = [train_df, test_merged_df]\n",
    "\n",
    "# for dataset in data:\n",
    "#     dataset['Embarked'] = dataset['Embarked'].fillna(common_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03754b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['Embarked'], axis=1)\n",
    "test_merged_df = test_merged_df.drop(['Embarked'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e666111",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking dataframes after dropping columns and merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffade991",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b24cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bf4170",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa2ef7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfb1c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#changed the fare na to 0 and changed type to interget from a float64\n",
    "data = [train_df, test_merged_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(0)\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dd7635",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca501198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Made genders bianary\n",
    "genders = {\"male\": 0, \"female\": 1}\n",
    "data = [train_df, test_merged_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Sex'] = dataset['Sex'].map(genders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb397763",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop([\"PassengerId\", \"Survived\"], axis=1)\n",
    "Y_train = train_df[\"Survived\"]\n",
    "X_test  = test_merged_df.drop([\"PassengerId\", \"Survived\"], axis=1).copy()\n",
    "Y_test = test_merged_df[\"Survived\"]\n",
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91c9f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X_test.columns\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2e38e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# X_scaler = StandardScaler().fit(X_train)\n",
    "# Y_scaler = StandardScaler().fit(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efff38c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_scaled = X_scaler.transform(X_train)\n",
    "# Y_train_scaled = Y_scaler.transform(Y_train)\n",
    "# X_test_scaled = X_scaler.transform(X_test)\n",
    "# Y_test_scaled = Y_scaler.transform(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065303e3",
   "metadata": {},
   "source": [
    "# Model Building and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb90b99",
   "metadata": {},
   "source": [
    "Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caae838",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(max_iter=1000)\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa8e341",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542850b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "logistic_regression = accuracy_score(Y_test,prediction)*100\n",
    "logistic_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00856fe",
   "metadata": {},
   "source": [
    "Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3d3986",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=1000)\n",
    "random_forest.fit(X_train, Y_train)\n",
    "ran_forest = random_forest.score(X_train, Y_train)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4fae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ran_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d29ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = random_forest.feature_importances_\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ff972c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We can sort the features by their importance\n",
    "sorted(zip(random_forest.feature_importances_, feature_names), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df37af59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "feature_imp = pd.Series(random_forest.feature_importances_, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "#print(\"Accuracy: {}\".format(metrics.accuracy_score(y_test, y_pred)))\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "# Add labels to your graph\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title(\"Visualizing Important Features\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e096fc3a",
   "metadata": {},
   "source": [
    "Support Vector Machine Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb15115",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "SVC = SVC()\n",
    "SVC.fit(X_train, Y_train)\n",
    "predictions = SVC.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c7baca",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Calculate classification report\n",
    "from sklearn.metrics import accuracy_score\n",
    "SVCAC = accuracy_score(Y_test,predictions)*100\n",
    "SVCAC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfefc4c4",
   "metadata": {},
   "source": [
    "K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e0fb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, Y_train)\n",
    "    train_score = knn.score(X_train, Y_train)\n",
    "    test_score = knn.score(X_test, Y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n",
    "    \n",
    "plt.plot(range(1, 20, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 20, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5bfe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=9)\n",
    "knn.fit(X_train, Y_train)\n",
    "knn = knn.score(X_test, Y_test)*100\n",
    "knn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f65368",
   "metadata": {},
   "source": [
    "Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f450db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "decision_tree = tree.DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, Y_train)\n",
    "prediction = decision_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dd5dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = accuracy_score(Y_test,prediction)*100\n",
    "decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d25977b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    \"Model\" : [\"Logistic Regression\", \"Random Forest\", \"Support Vector Machine\", \"K Nearest Neighbors\", \"Decision Tree\"],\n",
    "    \"Score\" : [logistic_regression, ran_forest, SVCAC, knn, decision_tree]})\n",
    "\n",
    "results_df = results.sort_values(by = \"Score\", ascending = False)\n",
    "results_df = results_df.set_index(\"Model\")\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f2a30d",
   "metadata": {},
   "source": [
    "# Random Forest Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25da839",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prediction person data (Pclass = 1, 2, or 3)\n",
    "Pclass = 3\n",
    "Age = 22\n",
    "SibSp = 1\n",
    "Sex = 0\n",
    "Parch = 0\n",
    "Fare = 7\n",
    "\n",
    "\n",
    "new_person = np.array([[Pclass, Sex, Age, SibSp, Parch, Fare]])\n",
    "new_person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d227c121",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pclass = 3\n",
    "Age = 45\n",
    "SibSp = 1\n",
    "Parch = 2\n",
    "Fare = 20\n",
    "Sex = 0\n",
    "new_person2 = np.array([[Pclass, Sex, Age, SibSp, Parch, Fare]])\n",
    "new_person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0b7234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict whether or not the person survives\n",
    "rf_predictions_1 = random_forest.predict(new_person)\n",
    "if rf_predictions_1 == 0:\n",
    "    print(f\"This person would probably perish on the Titanic\")\n",
    "else:\n",
    "    print(f\"This person would probably survive on the Titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6133c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf_predictions_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93252dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict whether or not the person survives\n",
    "rf_predictions_2 = random_forest.predict(new_person2)\n",
    "if rf_predictions_2 == 0:\n",
    "    print(f\"This person would probably perish on the Titanic\")\n",
    "else:\n",
    "    print(f\"This person would probably survive on the Titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc67375b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf_predictions_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d740b460",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
